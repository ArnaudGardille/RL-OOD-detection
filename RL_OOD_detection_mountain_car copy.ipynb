{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6b8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_ood import *\n",
    "path = Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21652f62",
   "metadata": {},
   "source": [
    "# OOD environments instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bc5c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gravity': 0.0025, 'Force': 0.001}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_values = MOUNTAIN_CAR_VALUES\n",
    "default_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc87f1",
   "metadata": {},
   "source": [
    "Each ood config differs from the defaut environment by only one attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a593e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = create_ood_values(default_values)\n",
    "ood_configs = get_ood_configs(default_values, values)\n",
    "len(ood_configs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b50458e",
   "metadata": {},
   "source": [
    "# Evaluate OOD impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71509566",
   "metadata": {},
   "source": [
    "### Original environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34148681",
   "metadata": {},
   "source": [
    "We train an agent on the original environment, and we evaluate its performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff6cabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-150.3, 18.56906028855526)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = instanciate_mountain_car(default_values)\n",
    "path_agent = path / 'Agents' / 'trained_mountain_car'\n",
    "#if os.path.exists(path_agent):\n",
    "#    agent = DQN.load(path_agent)\n",
    "#else:\n",
    "try:\n",
    "    agent = DQN.load(path/'Agents'/'trained_mountain_car', env=env)\n",
    "except:\n",
    "    agent = DQN('MlpPolicy', env, learning_rate=0.001, buffer_size=10000, learning_starts=50000, batch_size=128, tau=1.0, gamma=0.99, train_freq=4)\n",
    "    agent.learn(1000000, progress_bar=True)\n",
    "    agent.save(path_agent)\n",
    "evaluate(env, agent, nb_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f24c7dd",
   "metadata": {},
   "source": [
    "We evaluate this agent on several ood environments. We get the mean and std of the reward over 10 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b097d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_env = instanciate_mountain_car(ood_configs[-1])\n",
    "evaluate(ood_env, agent, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"number of ood values per attribute:\", len(values['Gravity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94edc440",
   "metadata": {},
   "source": [
    "### Impact of the ood on the reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values, values = get_mountain_car_values()\n",
    "results = {}\n",
    "std_results = {}\n",
    "\n",
    "original_env = instanciate_mountain_car(default_values)\n",
    "agent = A2C.load(path/'Agents'/'trained_mountain_car_10000', env=original_env)\n",
    "original_result, original_std_result = evaluate(original_env, agent, render=False)\n",
    "\n",
    "for config in tqdm(ood_configs):\n",
    "    if config['change'] not in results:\n",
    "        results[config['change']] = []\n",
    "        std_results[config['change']] = []\n",
    "    \n",
    "    ood_env = instanciate_mountain_car(config)\n",
    "    agent = A2C.load(path/'Agents'/'trained_mountain_car_10000', env=ood_env)\n",
    "    mean_reward, std_reward = evaluate(ood_env, agent, nb_episodes=100)\n",
    "    \n",
    "    results[config['change']].append(mean_reward)\n",
    "    std_results[config['change']].append(std_reward)\n",
    "    #print(config, mean_reward)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543509b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b892406",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in results:\n",
    "    fig, ax = plt.subplots(figsize=(10, 4), dpi=200)\n",
    "    ax.set_xscale('log')\n",
    "    \n",
    "    labels = copy(values[key])\n",
    "    labels.append(default_values[key])\n",
    "    labels = sorted(labels)\n",
    "    \n",
    "    width = np.array([2**i for i in range(-5, 0)] + [2**i for i in range(1, 5+1)]) #np.array(labels[1:]) - np.array(labels[:-1]) \n",
    "    width *= default_values[key]/3.0\n",
    "    #print(width, np.array([width[-1]]))\n",
    "    #width = np.concatenate((width, np.array([width[-1]])))/ 5\n",
    "    #print(width)\n",
    "    ax.bar(default_values[key], original_result, yerr=original_std_result, width=default_values[key]/3.0, label='Original')\n",
    "    ax.bar(values[key], results[key], yerr=std_results[key], width=width, label='OOD')\n",
    "    \n",
    "    ax.set_xlabel(key)\n",
    "    ax.set_ylabel('Mean episode duration')\n",
    "    ax.set_title('Impact of OOD regarding '+key)\n",
    "    ax.legend()\n",
    "    \"\"\"\n",
    "    ax.bar(str(default_values[key]), original_result, width=width)\n",
    "    labels = [str(x) for x in values[key]]\n",
    "    ax.bar(labels, results[key], width=width)\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0821a4d",
   "metadata": {},
   "source": [
    "# Create OOD detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48540f09",
   "metadata": {},
   "source": [
    "The configuration ood detector is relative to its default environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71944f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values, values = get_mountain_car_values()\n",
    "env = instanciate_mountain_car(default_values)\n",
    "ood_detector = MartingaleOODDetector(env, verbose=False)\n",
    "default_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817dfad",
   "metadata": {},
   "source": [
    "We have a low ood score on the delaut environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc93abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_detector.get_in_distrib_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d81c7",
   "metadata": {},
   "source": [
    "It should be higher on ood environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_config = get_ood_configs(default_values, values)[-1]\n",
    "ood_env = instanciate_mountain_car(ood_config)\n",
    "ood_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_score = ood_detector.test_ood(ood_env, nb_steps=100)\n",
    "ood_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b1fcdb",
   "metadata": {},
   "source": [
    "Let's compute the ood scores of the previously studies ood environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04ff4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values, values = get_mountain_car_values()\n",
    "mean_ood_scores = {}\n",
    "std_ood_scores = {}\n",
    "\n",
    "original_env = instanciate_mountain_car(default_values)\n",
    "agent = A2C.load(path/'Agents'/'trained_mountain_car_10000', env=original_env)\n",
    "ood_detector = MartingaleOODDetector(env)\n",
    "in_distrib_score = ood_detector.get_in_distrib_score()\n",
    "\n",
    "for config in tqdm(ood_configs):\n",
    "    if config['change'] not in mean_ood_scores:\n",
    "        mean_ood_scores[config['change']] = []\n",
    "        std_ood_scores[config['change']] = []\n",
    "    \n",
    "    ood_env = instanciate_mountain_car(config)\n",
    "    agent = A2C.load(path/'Agents'/'trained_mountain_car_10000', env=ood_env)\n",
    "    list_scores = np.array([ood_detector.test_ood(ood_env, nb_steps=100) for _ in range(10)])\n",
    "    ood_score = list_scores.mean()\n",
    "    std_score = list_scores.std()\n",
    "\n",
    "    #mean_reward, std_reward = evaluate(ood_env, agent, nb_episodes=10)\n",
    "\n",
    "    mean_ood_scores[config['change']].append(ood_score)\n",
    "    std_ood_scores[config['change']].append(std_score)\n",
    "    #print(config, mean_reward)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31865b0c",
   "metadata": {},
   "source": [
    "We now realise a plot of the mean reward and ood scores of each environment. The ones of the delaut environment are in darker colour at the middle of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf22d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ood_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ood_scores['Gravity'] > 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "{std_ood_scores[k] > 1.1 for k in std_ood_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "{std_ood_scores[k][6] for k in std_ood_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d67e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "from numpy import inf\n",
    "\n",
    "\n",
    "for key in tqdm(results):\n",
    "    fig, ax = plt.subplots(figsize=(10, 4), dpi=200)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    labels = copy(values[key])\n",
    "    labels.append(default_values[key])\n",
    "    labels = sorted(labels)\n",
    "    \n",
    "    #mean_ood_scores[key] = np.nan_to_num(mean_ood_scores[key], copy=True, nan=0.0, posinf=max(mean_ood_scores[key]), neginf=0)\n",
    "    #std_ood_scores[key] = np.nan_to_num(std_ood_scores[key], copy=True, nan=0.0, posinf=max(std_ood_scores[key]), neginf=0)\n",
    "\n",
    "    default_width = default_values[key]/6.0\n",
    "    width = np.array([2**i for i in range(-5, 0)] + [2**i for i in range(1, 5+1)]) #np.array(labels[1:]) - np.array(labels[:-1]) \n",
    "    width *= default_width\n",
    "    #print(width, np.array([width[-1]]))\n",
    "    #width = np.concatenate((width, np.array([width[-1]])))/ 5\n",
    "    #print(width)\n",
    "\n",
    "    ax.bar(default_values[key]- default_width/2, 1.0, width=default_width, label='Mean reward', color='darkgreen')\n",
    "    ax.bar(values[key]- width/2, results[key]/original_result, width=width,  color='green')\n",
    "\n",
    "    ax.bar(default_values[key]+default_width/2, 1.0, width=default_width, label='OOD score', color='darkorange')\n",
    "    ax.bar(values[key]+ width/2, mean_ood_scores[key]/in_distrib_score, width=width, color='orange', yerr=std_ood_scores[key])\n",
    "    \n",
    "    ax.set_xlabel(key)\n",
    "    ax.set_ylabel('Mean episode duration')\n",
    "    ax.set_title('Impact of OOD regarding '+key)\n",
    "\n",
    "    plt.legend() #prop={'size': 'medium'}, ncol=2)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12474d80",
   "metadata": {},
   "source": [
    "We add as maning in distribution examples and there are ood examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_env = instanciate_mountain_car(default_values)\n",
    "agent = A2C.load(path/'Agents'/'trained_mountain_car_10000', env=original_env)\n",
    "\n",
    "list_scores = []\n",
    "for _ in trange(5*18):\n",
    "    list_scores.append(np.array([ood_detector.test_ood(original_env, nb_steps=100) for _ in range(10)]).mean())\n",
    "\n",
    "mean_ood_scores['None'] = list_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb3e0c9",
   "metadata": {},
   "source": [
    "# Detection speed at a fixed threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68fa83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_ood_scores['Gravity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7c2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8efc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_env = instanciate_mountain_car(default_values)\n",
    "list_scores = np.array([ood_detector.test_ood(original_env, nb_steps=1000) for _ in range(100)])\n",
    "ood_score = list_scores.mean()\n",
    "std_score = list_scores.std()\n",
    "\n",
    "ood_score, std_score, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef652bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_ood import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = ood_score + 10*std_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([ood_detector.test_ood(original_env, nb_steps=100) for _ in range(100)]) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32eb9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[:20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MartingaleOODDetector():\n",
    "    def __init__(self, env: gym.Env, verbose=False, *args, **kwargs) -> None:\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # training the model\n",
    "        X_pred, y_pred = create_dataset(env, nb_steps=10000)\n",
    "        self.pred_model = MultiOutputRegressor(KNeighborsRegressor()).fit(X_pred, y_pred)\n",
    "        #self.conf_model = conf_model\n",
    "\n",
    "        self.in_distrib_score = self.test_ood(env)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Anomaly score of the training distribution: \", self.in_distrib_score)\n",
    "\n",
    "    def get_in_distrib_score(self):\n",
    "        return self.in_distrib_score\n",
    "\n",
    "    def test_ood(self, env, nb_steps=1000):\n",
    "        \"\"\"\n",
    "        Compute the ood score\n",
    "        \"\"\"\n",
    "        X_val, y_val = create_dataset(env, nb_steps)\n",
    "        errors = np.abs((self.pred_model.predict(X_val) - y_val))\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Absolute error\")\n",
    "            print(\"Mean: \", errors.mean())\n",
    "            print(\"Std: \", errors.std())\n",
    "            print()\n",
    "\n",
    "\n",
    "        # Calibration of the ood detector\n",
    "        pre_ood_score = martingale(compute_p_values(errors))   \n",
    "        ood_score = nb_steps * np.log(1 + pre_ood_score) #/nb_steps\n",
    "        #print(\"corrected score \", np.log10(ood_score)/nb_steps)\n",
    "        return ood_score\n",
    "\n",
    "    def stop_above_threshold(self, env, threshold, start_at=50, nb_steps=1000):\n",
    "        \"\"\"\n",
    "        Compute the number of step for the ood score to go above the threshold\n",
    "        \"\"\"\n",
    "        X_val, y_val = create_dataset(env, nb_steps)\n",
    "\n",
    "        for step in range(start_at,nb_steps):\n",
    "            errors = np.abs((self.pred_model.predict(X_val[:step]) - y_val[:step]))\n",
    "\n",
    "            if self.verbose:\n",
    "                print(\"Absolute error\")\n",
    "                print(\"Mean: \", errors.mean())\n",
    "                print(\"Std: \", errors.std())\n",
    "                print()\n",
    "\n",
    "\n",
    "            # Calibration of the ood detector\n",
    "            pre_ood_score = martingale(compute_p_values(errors))   \n",
    "            ood_score = step * np.log(1 + pre_ood_score) #/nb_steps\n",
    "            #print(\"corrected score \", np.log10(ood_score)/nb_steps)\n",
    "            if ood_score > threshold:\n",
    "                return step, ood_score\n",
    "        return nb_steps, ood_score\n",
    "\n",
    "    def save(self, path):\n",
    "        np.save(path / 'nonconformity_scores.npy', self.nonconformity_scores)\n",
    "        \n",
    "    def load(self, path):\n",
    "        self.nonconformity_scores = np.load(path / 'nonconformity_scores.npy')\n",
    "\n",
    "\n",
    "\n",
    "ood_detector = MartingaleOODDetector(original_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc21077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [ood_detector.test_ood(original_env, nb_steps=n) for n in range(1,1000)]\n",
    "plt.plot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1568327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_detector.stop_above_threshold(original_env, threshold, start_at=50, nb_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_detector.stop_above_threshold(original_env, threshold, start_at=50, nb_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_values, values = get_mountain_car_values()\n",
    "mean_ood_stops = {}\n",
    "std_ood_stops = {}\n",
    "\n",
    "original_env = instanciate_mountain_car(default_values)\n",
    "agent = A2C.load(path/'Agents'/'trained_mountain_car_10000', env=original_env)\n",
    "ood_detector = MartingaleOODDetector(env)\n",
    "in_distrib_score = ood_detector.get_in_distrib_score()\n",
    "\n",
    "for config in tqdm(ood_configs):\n",
    "    if config['change'] not in mean_ood_scores:\n",
    "        mean_ood_scores[config['change']] = []\n",
    "        std_ood_scores[config['change']] = []\n",
    "    \n",
    "    ood_env = instanciate_mountain_car(config)\n",
    "    agent = A2C.load(path/'Agents'/'trained_mountain_car_10000', env=ood_env)\n",
    "    list_stops = np.array([ood_detector.stop_above_threshold(original_env, threshold, start_at=30, nb_steps=1000)[0] for _ in range(10)])\n",
    "    mean_ood_stop = list_stops.mean()\n",
    "    std_ood_stop = list_stops.std()\n",
    "\n",
    "    #mean_reward, std_reward = evaluate(ood_env, agent, nb_episodes=10)\n",
    "\n",
    "    mean_ood_stops[config['change']].append(mean_ood_stop)\n",
    "    std_ood_stops[config['change']].append(std_ood_stop)\n",
    "    #print(config, mean_reward)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ab19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "from numpy import inf\n",
    "\n",
    "\n",
    "for key in tqdm(results):\n",
    "    fig, ax = plt.subplots(figsize=(10, 4), dpi=200)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    labels = copy(values[key])\n",
    "    labels.append(default_values[key])\n",
    "    labels = sorted(labels)\n",
    "    \n",
    "    #mean_ood_scores[key] = np.nan_to_num(mean_ood_scores[key], copy=True, nan=0.0, posinf=max(mean_ood_scores[key]), neginf=0)\n",
    "    #std_ood_scores[key] = np.nan_to_num(std_ood_scores[key], copy=True, nan=0.0, posinf=max(std_ood_scores[key]), neginf=0)\n",
    "\n",
    "    default_width = default_values[key]/6.0\n",
    "    width = np.array([2**i for i in range(-5, 0)] + [2**i for i in range(1, 5+1)]) #np.array(labels[1:]) - np.array(labels[:-1]) \n",
    "    width *= default_width\n",
    "    #print(width, np.array([width[-1]]))\n",
    "    #width = np.concatenate((width, np.array([width[-1]])))/ 5\n",
    "    #print(width)\n",
    "\n",
    "    ax.bar(default_values[key]- default_width/2, 1.0, width=default_width, label='Mean stop', color='darkgreen')\n",
    "    ax.bar(values[key]- width/2, results[key], width=width,  color='green')\n",
    "\n",
    "    ax.bar(default_values[key]+default_width/2, 1000.0, width=default_width, label='OOD stop', color='darkorange')\n",
    "    ax.bar(values[key]+ width/2, mean_ood_stops[key], width=width, color='orange', yerr=std_ood_scores[key])\n",
    "    \n",
    "    ax.set_xlabel(key)\n",
    "    ax.set_ylabel('Mean episode duration')\n",
    "    ax.set_title('Impact of OOD regarding '+key)\n",
    "\n",
    "    plt.legend() #prop={'size': 'medium'}, ncol=2)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593cd96c",
   "metadata": {},
   "source": [
    "# Computation of the AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AUC(mean_ood_scores, plot=True, verbose=False):\n",
    "    TPRs = []\n",
    "    FPRs = []\n",
    "\n",
    "    thresholds = [10**(-i/10) for i in range(-50, 50+1)]\n",
    "    for threshold in thresholds:\n",
    "        false_pos=0\n",
    "        false_neg=0\n",
    "        true_pos=0\n",
    "        true_neg=0\n",
    "\n",
    "        for key in mean_ood_scores:\n",
    "            if str(key) != 'None': # Env OOD\n",
    "                for test_res in mean_ood_scores[key]:\n",
    "\n",
    "                    if test_res<threshold: # Not detected as OOD\n",
    "                        false_neg +=1\n",
    "                    else:\n",
    "                        true_pos +=1\n",
    "            else: # Env standard\n",
    "                for test_res in mean_ood_scores[key]:\n",
    "\n",
    "                    if test_res>threshold: # Detected as OOD\n",
    "                        false_pos +=1\n",
    "                    else:\n",
    "                        true_neg +=1\n",
    "\n",
    "\n",
    "        try:\n",
    "            tpr = true_pos/(true_pos+false_neg)\n",
    "        except ZeroDivisionError:\n",
    "            print('error computing tpr')\n",
    "            continue\n",
    "            tpr = 1.0\n",
    "        \n",
    "        try:\n",
    "            fpr = false_pos/(false_pos+true_neg)\n",
    "        except ZeroDivisionError:\n",
    "            print('error computing fpr')\n",
    "            continue\n",
    "\n",
    "        if verbose:\n",
    "            print(threshold)\n",
    "            print('TP', true_pos, 'FP',false_pos)\n",
    "            print('FN', false_neg, 'TN',true_neg)\n",
    "            print()\n",
    "            print(tpr, fpr)\n",
    "        TPRs.append(tpr)\n",
    "        FPRs.append(fpr)\n",
    "        #AUC += tpr/len(thresholds)\n",
    "\n",
    "    if verbose:\n",
    "        plt.title(\"TPR and FPR curves\")\n",
    "        plt.plot(TPRs, label='TPR')\n",
    "        plt.plot(FPRs, label='FPR')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    #print('AUC: ', AUC)\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.plot(FPRs, TPRs,'-*')\n",
    "    plt.xlabel('TPR')\n",
    "    plt.ylabel('FPR')\n",
    "    plt.show()\n",
    "\n",
    "    AUC = integrate.simps(x=FPRs, y=TPRs, even='avg')\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40800f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_AUC(mean_ood_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('rl_ood_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f2183d0c43580188c5e5c81464367ab4184a790cd2d589552e2fcc0f09180be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
