{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from itertools import product\n",
    "from stable_baselines3 import A2C\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import copy\n",
    "from tqdm import trange\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dd482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd()\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cartpole_values():\n",
    "    default_values = {}\n",
    "    values = {}\n",
    "\n",
    "    default_values['Gravity'] = 9.8\n",
    "    values['Gravity'] = [0.98, 1.09, 1.23, 1.4, 1.63, 1.96, 2.45, 3.27, 4.9, 19.6, 29.4, 39.2, 49.0, 58.8, 68.6, 78.4, 88.2, 98.0]\n",
    "\n",
    "    default_values['Mass_cart'] = 1.0\n",
    "    values['Mass_cart'] = [0.1, 0.1111, 0.125, 0.1429, 0.1667, 0.2, 0.25, 0.3333, 0.5, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "\n",
    "    default_values['Length_pole'] = 0.5\n",
    "    values['Length_pole'] = [0.05, 0.0556, 0.0625, 0.0714, 0.0833, 0.1, 0.125, 0.1667, 0.25, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
    "\n",
    "    default_values['Mass_pole'] = 0.1\n",
    "    values['Mass_pole'] = [0.01, 0.0111, 0.0125, 0.0143, 0.0167, 0.02, 0.025, 0.0333, 0.05, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "    default_values['Force_magnitude'] = 10.0\n",
    "    values['Force_magnitude'] = [1.0, 1.1111, 1.25, 1.4286, 1.6667, 2.0, 2.5, 3.3333, 5.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
    "\n",
    "    return default_values, values\n",
    "\n",
    "def instanciate_cartpole(gravity, mass_cart, length_pole, mass_pole, force_magnitude):\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    env.gravity = gravity\n",
    "    env.masscart = mass_cart\n",
    "    env.masspole = mass_pole\n",
    "    env.total_mass = env.masspole + env.masscart\n",
    "    env.length = length_pole  # actually half the pole's length\n",
    "    env.polemass_length = env.masspole * env.length\n",
    "    env.force_mag = force_magnitude\n",
    "    return env\n",
    "\n",
    "#instanciate_cartpole()\n",
    "default_values, values = get_cartpole_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d2437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pendulum_values():\n",
    "    default_values = {}\n",
    "    values = {}\n",
    "\n",
    "    default_values['Gravity'] = 10.0\n",
    "    values['Gravity'] = [0.5, 1.0, 2.0, 5.0, 20.0, 50.0, 100.0, 200.0]\n",
    "\n",
    "    default_values['Mass_pole'] = 1.0\n",
    "    values['Mass_pole'] = [0.05, 0.1, 0.2, 0.5, 2.0, 5.0, 10.0, 20.0]\n",
    "\n",
    "    default_values['Length_pole'] = 1.0\n",
    "    values['Length_pole'] = [0.05, 0.1, 0.2, 0.5, 2.0, 5.0, 10.0, 20.0]\n",
    "    \n",
    "    default_values['Max_speed'] = 8.0\n",
    "    values['Max_speed'] = [0.4, 0.8, 1.6, 4.0, 16.0, 40.0, 80.0, 160.0]\n",
    "\n",
    "    default_values['Max_torque'] = 2.0\n",
    "    values['Max_torque'] = [0.1, 0.2, 0.4, 1.0, 4.0, 10.0, 20.0, 40.0]\n",
    "\n",
    "    return default_values, values\n",
    "\n",
    "def instanciate_pendulum(gravity, mass_pole, length_pole, max_speed, max_torque):\n",
    "    env = gym.make(\"Pendulum-v1\")\n",
    "    env.max_speed = max_speed\n",
    "    env.max_torque = max_torque\n",
    "    env.g = gravity\n",
    "    env.m = mass_pole\n",
    "    env.l = length_pole\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0413c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_combinaisons(values):\n",
    "    return [x for x in product(*list(values.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = instanciate_cartpole(*list(default_values.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "#agent = A2C.load(path/'Agents'/'Pendulum-v1.zip', env=env)\n",
    "\n",
    "agent = A2C.load(path/'Agents'/'CartPole-v1.zip', env=env)\n",
    "\n",
    "\n",
    "for _ in range(1000):\n",
    "    action, _state = agent.predict(observation)\n",
    "    #env.action_space.sample()\n",
    "    observation, reward, terminated, info = env.step(action)\n",
    "    #env.render()\n",
    "\n",
    "    if terminated:\n",
    "        observation = env.reset()\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, limits):\n",
    "    \"\"\"low, high = limits\n",
    "    norm_x = (x - low)/(high - low)\n",
    "    norm_x = (norm_x-0.5)*2.0\n",
    "    assert torch.all(torch.abs(norm_x) <= 1.0)\n",
    "    return norm_x\"\"\"\n",
    "    return x\n",
    "\n",
    "def denormalize(x, limits):\n",
    "    \"\"\"x = 0.5*x+0.5\n",
    "    low, high = limits\n",
    "    return x * (high - low) + low\"\"\"\n",
    "    return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, size_hidden_layers, bias=True, final_activation=None, dropout=0.1):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.size_hidden_layers = size_hidden_layers\n",
    "\n",
    "        layer = []\n",
    "        previous_input_size = input_size\n",
    "        for size_hidden_layer in size_hidden_layers:\n",
    "            layer.append(nn.Linear(previous_input_size, size_hidden_layer, bias=bias))\n",
    "            layer.append(nn.ReLU())\n",
    "            layer.append(torch.nn.Dropout(dropout))\n",
    "            previous_input_size = size_hidden_layer\n",
    "\n",
    "        layer.append(nn.Linear(previous_input_size, output_size, bias=False))\n",
    "\n",
    "        if final_activation is not None:\n",
    "            layer.append(final_activation)\n",
    "\n",
    "        \n",
    "\n",
    "        self.net = nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, X):   \n",
    "        if not torch.is_tensor(X):  \n",
    "            X = torch.tensor(X)\n",
    "        X = X.reshape(-1, self.input_size)\n",
    "        return self.net(X)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ddbee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb90aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_space_limits(space):\n",
    "    if isinstance(space, gym.spaces.Discrete):\n",
    "        return np.array([0.0], dtype=np.float32),  np.array([float(env.action_space.n -1)], dtype=np.float32)\n",
    "    else:\n",
    "        return space.low, space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e62f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(gym.Wrapper):\n",
    "    def __init__(self, env, size, verbose=False, *args, **kwargs):\n",
    "        super().__init__(env, *args, **kwargs)\n",
    "        self.size = size\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.obs_limits = get_space_limits(env.observation_space)  \n",
    "        self.act_limits = get_space_limits(env.action_space)\n",
    "        \n",
    "        self.state_size = self.obs_limits[0].shape[0]\n",
    "        self.action_size = self.act_limits[0].shape[0]\n",
    "       \n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        \n",
    "        self.history_obs = np.roll(self.history_obs, -self.state_size)\n",
    "        self.history_obs[-1] = obs\n",
    "        \n",
    "        self.history_action = np.roll(self.history_action, -self.action_size)\n",
    "        self.history_action[-1] = action\n",
    "\n",
    "        if self.verbose:\n",
    "            print(self.history_obs)\n",
    "            print(self.history_action)\n",
    "        \n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self, *args, **kwargs):\n",
    "        observation = self.env.reset(*args, **kwargs)\n",
    "        self.history_obs = np.full((self.size, self.state_size), observation)\n",
    "        self.history_action = np.full((self.size, self.action_size), 0)\n",
    "        return observation\n",
    "        \n",
    "\n",
    "    def get_history(self, concat=False):\n",
    "        if concat:\n",
    "            return np.concatenate((self.history_obs, self.history_action), axis=1)\n",
    "        else:\n",
    "            return self.history_obs, self.history_action\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = instanciate_cartpole(*list(default_values.values()))\n",
    "mem_env = Memory(env, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623147fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_env.reset()\n",
    "mem_env.step(0)\n",
    "mem_env.get_history(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12591c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a51d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6197b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GaussianModel():\n",
    "    def __init__(self, env, size_hidden_layers=[1000, 500, 100], size_memory=5, confidence=True, dropout=0.1) -> None:\n",
    "        self.size_memory = size_memory\n",
    "        \n",
    "        self.obs_limits = get_space_limits(env.observation_space)  \n",
    "        self.act_limits = get_space_limits(env.action_space)\n",
    "        \n",
    "        self.state_size = self.obs_limits[0].shape[0]\n",
    "        self.action_size = self.act_limits[0].shape[0]\n",
    "        \n",
    "        input_size, output_size = size_memory*(self.state_size + self.action_size), self.state_size\n",
    "        \n",
    "        self.pred_model = MLP(input_size, output_size, size_hidden_layers, bias=True, final_activation=None, dropout=dropout)\n",
    "        \n",
    "        self.confidence = confidence\n",
    "        if self.confidence:\n",
    "            # nn.LeakyReLU has the advantage to have a symetrical derivative in any point excpet 0.\n",
    "            # using for example the Softplus function would bias the variance estimation, and be problematic with the test\n",
    "            self.conf_model = MLP(input_size, output_size, size_hidden_layers, bias=True, final_activation=nn.LeakyReLU(-1.0), dropout=dropout)\n",
    "\n",
    "        #self.history_size = history_size\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def predict_diff_states(self, state, action):\n",
    "        state = torch.tensor(state).reshape(self.size_memory*self.state_size).float()     \n",
    "        action = torch.tensor(action).reshape(self.size_memory*self.action_size).float()     \n",
    "\n",
    "        normalized_state = normalize(state, self.obs_limits)        \n",
    "        normalized_action = normalize(action, self.act_limits)\n",
    "        \n",
    "        X = torch.cat((normalized_state, normalized_action), dim=0)\n",
    "        X.requires_grad = True\n",
    "        pred_diff = self.pred_model(X) #.detach() \n",
    "        \n",
    "        if self.confidence:\n",
    "            std = self.conf_model(X) #.detach()\n",
    "        else:\n",
    "            std = torch.ones(pred_diff.shape).to(device)\n",
    "        \n",
    "        return pred_diff[0], std[0]\n",
    "\n",
    "    def save(self, folder):\n",
    "        torch.save(self.pred_model.cpu(), folder / 'pred_model.pth')\n",
    "        if self.confidence:\n",
    "            torch.save(self.conf_model.cpu(), folder / 'conf_model.pth')\n",
    "        joblib.dump(self.scaler_X, folder / 'scaler_X.bin', compress=True)\n",
    "        joblib.dump(self.scaler_Y, folder / 'scaler_Y.bin', compress=True)\n",
    "\n",
    "    def load(self, folder):\n",
    "        self.pred_model = torch.load(folder / 'pred_model.pth').to(device)\n",
    "        if self.confidence:\n",
    "            self.conf_model = torch.load(folder / 'conf_model.pth').to(device)\n",
    "        self.scaler_X = joblib.load(folder / 'scaler_X.bin')\n",
    "        self.scaler_Y = joblib.load(folder / 'scaler_Y.bin')\n",
    "\n",
    "\n",
    "    def fit(self, env, nb_steps = 1000, num_epochs=25, lr :float =0.1):\n",
    "        \n",
    "        env = Memory(env, self.size_memory)\n",
    "        models = {'pred':self.pred_model}\n",
    "        if self.confidence:\n",
    "            models['conf'] = self.conf_model\n",
    "  \n",
    "        for model_type, model in models.items():\n",
    "            model.train()\n",
    "\n",
    "            # Observe that all parameters are being optimized\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "            # Decay LR by a factor of 0.1 every 7 epochs\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "            writer = SummaryWriter('tensorboard/model_learning_'+model_type)\n",
    "            since = time.time()\n",
    "\n",
    "            best_loss = 1e10\n",
    "\n",
    "            pbar = trange(num_epochs)\n",
    "            for epoch in pbar:\n",
    "                #print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "                #print('-' * 10)\n",
    "\n",
    "                # Each epoch has a training and validation phase\n",
    "                phase_loss = {}\n",
    "                    \n",
    "                observation = env.reset()\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                for t in range(nb_steps):\n",
    "                    #action, _state = agent.predict(observation)\n",
    "                    action = env.action_space.sample()\n",
    "                    previous_obs = observation\n",
    "                    observation, reward, terminated, info = env.step(action)\n",
    "                    history = env.get_history(True)\n",
    "                    \n",
    "                    history = torch.FloatTensor(history).reshape(self.size_memory*self.state_size)     \n",
    "                    #env.render()\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(True):\n",
    "                        #print('inputs: ', inputs.shape)\n",
    "                        #gap = (observation - previous_obs - pred_diff)/std\n",
    "                        pred_diff, std = self.predict_diff_states(previous_obs, action)\n",
    "\n",
    "                        if model_type == 'conf':\n",
    "                            loss = self.criterion(torch.abs(observation - previous_obs - pred_diff), std)\n",
    "                            #loss = self.criterion((outputs - labels)**2, vari)\n",
    "                        else:\n",
    "                            loss = self.criterion((observation - previous_obs - pred_diff)/std, torch.zeros(1))\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        # statistics\n",
    "                        running_loss += loss.item()\n",
    "                        \n",
    "                    if terminated:\n",
    "                        observation = env.reset()\n",
    "                        \n",
    "                    \n",
    "                scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / nb_steps\n",
    "                    #print(f'{phase} Loss: {epoch_loss:.4f}')\n",
    "                    #print()\n",
    "\n",
    "                    # deep copy the model\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "\n",
    "                writer.add_scalar(model_type+' Loss', epoch_loss, epoch)\n",
    "                writer.flush()\n",
    "                \n",
    "                pbar.set_description(\"Loss: %2.4f\" % (epoch_loss))\n",
    "\n",
    "            time_elapsed = time.time() - since\n",
    "            print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "            print(f'Best val Loss: {best_loss:4f}')\n",
    "\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "        print()\n",
    "        return best_loss\n",
    "\n",
    "    def visualize(self, env, steps=100, saving_path=Path.cwd() / 'Plots', plot=True, figsize=(10, 4), dpi=300):\n",
    "        os.makedirs(saving_path, exist_ok=True)\n",
    "        writer = SummaryWriter('tensorboard/visualize_model')\n",
    "        \n",
    "        self.pred_model = self.pred_model.to(device).eval()\n",
    "        if self.confidence:\n",
    "            self.conf_model = self.conf_model.to(device).eval()\n",
    "        \n",
    "        observations = []\n",
    "        actions = []\n",
    "        pred_diffs = []\n",
    "        real_diffs = []\n",
    "        pred_stds = []\n",
    "\n",
    "        done=True\n",
    "\n",
    "        if plot:\n",
    "            pbar = trange(steps)\n",
    "        else:\n",
    "            pbar = range(steps)\n",
    "\n",
    "        observation = torch.FloatTensor(env.reset()).reshape(self.state_size)     \n",
    "        running_loss = 0.0\n",
    "\n",
    "        for t in pbar:\n",
    "            #action, _state = agent.predict(observation)\n",
    "            action = env.action_space.sample()\n",
    "            previous_obs = observation\n",
    "            observation, reward, terminated, info = env.step(action)\n",
    "            observation = torch.FloatTensor(observation).reshape(self.state_size)     \n",
    "            env.render()\n",
    "\n",
    "\n",
    "            #print('inputs: ', inputs.shape)\n",
    "            #gap = (observation - previous_obs - pred_diff)/std\n",
    "            pred_diff, std = self.predict_diff_states(previous_obs, action)\n",
    "            pred_diff, std = pred_diff.detach(), std.detach()\n",
    "\n",
    "\n",
    "            loss_conf = self.criterion(torch.abs(observation - previous_obs - pred_diff), std)\n",
    "\n",
    "            loss_pred = self.criterion((observation - previous_obs - pred_diff)/std, torch.zeros(1))\n",
    "\n",
    "            # statistics\n",
    "            #running_loss += loss.item()\n",
    "\n",
    "            if terminated:\n",
    "                observation = env.reset()\n",
    "\n",
    "            if plot:\n",
    "                pbar.set_description(\"loss_pred: %2.4f, loss_conf: %2.4f\" % (loss_pred, loss_conf))\n",
    "\n",
    "\n",
    "\n",
    "            #print(f'{phase} Loss: {epoch_loss:.4f}')\n",
    "            #print()\n",
    "            #writer.add_scalars('run_14h', {'xsinx':np.sin(t), 'xcosx':np.cos(t), 'tanx': np.tan(t)}, t)\n",
    "            for state_id in range(self.state_size):\n",
    "                writer.add_scalar('observation/'+str(state_id), np.array(observation)[state_id], t)\n",
    "                d =  {'predicted': np.array(pred_diff)[state_id], 'real': (np.array(observation) - np.array(previous_obs))[state_id]}\n",
    "\n",
    "                writer.add_scalars('observation_difference/'+str(state_id),d, t)\n",
    "                \n",
    "                writer.add_scalar('observation_std/'+str(state_id), np.array(std)[state_id], t)\n",
    "\n",
    "            for action_id in range(self.action_size):\n",
    "                writer.add_scalar('action/'+str(action_id), np.array(action).reshape(self.action_size)[action_id], t)\n",
    "                \n",
    "            writer.flush()\n",
    "            \n",
    "            observations.append(np.array(observation)) #.numpy()\n",
    "            actions.append(np.array(action).reshape(self.action_size))\n",
    "            pred_diffs.append(np.array(pred_diff))\n",
    "            real_diffs.append(np.array(observation) - np.array(previous_obs))\n",
    "            pred_stds.append(np.array(std))\n",
    "\n",
    "            \"\"\"writer.add_scalar('state/'+str(state_id), distance.numpy(), i)\n",
    "            writer.add_scalar('state/speed', speed.numpy(), i)\n",
    "            writer.add_scalar('action', action.numpy(), i)\n",
    "            writer.add_scalar('diff_distances/prediction', pred_diff_distance.numpy(), i)\n",
    "            writer.add_scalar('diff_distances/reality', pred_diff_distance.numpy(), i)\n",
    "            writer.add_scalar('diff_distances/variance', var_distance.numpy(), i)\n",
    "\n",
    "            writer.add_scalar('diff_speed/prediction', pred_diff_speed.numpy(), i)\n",
    "            writer.add_scalar('diff_speed/reality', real_diff_speed.numpy(), i)\n",
    "            writer.add_scalar('diff_speed/variance', var_speed.numpy(), i)\n",
    "            writer.flush()\"\"\"\n",
    "            \n",
    "        observations = np.array(observations)\n",
    "        actions = np.array(actions)\n",
    "        pred_diffs = np.array(pred_diffs)\n",
    "        real_diffs = np.array(real_diffs)\n",
    "        pred_stds = np.array(pred_stds)\n",
    "        \n",
    "        for state_id in range(self.state_size):\n",
    "            \n",
    "\n",
    "            evolution = {}\n",
    "            evolution['prediction'] = np.array(pred_diffs[:,state_id])\n",
    "            evolution['reality'] = np.array(real_diffs[:,state_id])\n",
    "            evolution_df = pd.DataFrame(data=evolution)\n",
    "            if plot:\n",
    "                fig = plt.figure(dpi=dpi, figsize=figsize) \n",
    "                evolution_df.plot(title='Evolution of the differences of observation component ' + str(state_id), ax = plt.gca())\n",
    "                #plt.ylabel('Distance (m)')\n",
    "                plt.xlabel('Steps')\n",
    "                plt.savefig(saving_path / 'evol_diff_obs', bbox_inches='tight')\n",
    "                plt.show()\n",
    "\n",
    "        for action_id in range(self.action_size):\n",
    "            \n",
    "            evolution = {}\n",
    "            evolution['prediction'] = np.array(actions[:,action_id])\n",
    "            evolution['reality'] = np.array(actions[:,action_id])\n",
    "            evolution_df = pd.DataFrame(data=evolution)\n",
    "            if plot:\n",
    "                fig = plt.figure(dpi=dpi, figsize=figsize) \n",
    "                evolution_df.plot(title='Evolution of the differences of action component ' + str(action_id), ax = plt.gca())\n",
    "                #plt.ylabel('Distance (m)')\n",
    "                plt.xlabel('Steps')\n",
    "                plt.savefig(saving_path / 'evol_act', bbox_inches='tight')\n",
    "                plt.show()\n",
    "\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "        error_diff_distances = diff_distance_dict['prediction'] - diff_distance_dict['reality']\n",
    "        if plot:\n",
    "            plot_error_variance(error_diff_distances, var_distances, saving_path, 'distance', figsize=figsize, unit='m')\n",
    "            plot_error_corrected(error_diff_distances, var_distances, saving_path, 'distance', figsize=figsize, dpi=dpi)\n",
    "            plot_error_confidence_from_variance(error_diff_distances, var_distances, saving_path, 'distance', figsize=figsize, dpi=dpi, unit='m')\n",
    "\n",
    "        error_diff_speeds = diff_speed_dict['prediction'] - diff_speed_dict['reality']\n",
    "        if plot:\n",
    "            plot_error_variance(error_diff_speeds, var_speeds, saving_path, 'speed', figsize=figsize, unit='m/s')\n",
    "            plot_error_corrected(error_diff_speeds, var_speeds, saving_path, 'speed', figsize=figsize, dpi=dpi)\n",
    "            plot_error_confidence_from_variance(error_diff_speeds, var_speeds, saving_path, 'speed', figsize=figsize, dpi=dpi, unit='m/s')\n",
    "        \"\"\"\n",
    "        return observations, actions, pred_diffs, real_diffs, pred_stds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa04fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianModel(env, confidence=False, dropout=0.0)\n",
    "model.fit(env, nb_steps=100, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db602d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.visualize(env, steps=100)\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c01fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57714a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(1)#.reshape( 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.abs([-2, 1, 3]) <= 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869cdeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
